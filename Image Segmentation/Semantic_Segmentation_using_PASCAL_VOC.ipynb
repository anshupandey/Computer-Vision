{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Segmentation using PASCAL_VOC.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Computer-Vision/blob/master/Image%20Segmentation/Semantic_Segmentation_using_PASCAL_VOC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWBgMpKaVazv"
      },
      "source": [
        "#### Download Pascal VOC Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdw3P9V9VuAe"
      },
      "source": [
        "#Get PASCAL VOC dataset\n",
        "!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMYKmyKdXKey"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvUWe5HNYxi-"
      },
      "source": [
        "#unzip data\n",
        "!tar -xf VOCtrainval_06-Nov-2007.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe3Gx118vnMA"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNh2k-MTs7Kc"
      },
      "source": [
        "!ls -l images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcuOZZ1vaSII"
      },
      "source": [
        "!ls -l masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KblkZlmEYFg-"
      },
      "source": [
        "Images and Masks are unzipped"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14CoGh6cXgGp"
      },
      "source": [
        "!ls -l images | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFo4n2BcYedM"
      },
      "source": [
        "#### Visualizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oDd72zQYgJB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import PIL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knAsNl78zH2O"
      },
      "source": [
        "Read training images and build a dataframe with IDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "134AWxJW3kfm"
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ9qdY2BICIh"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUelt28h0gC2"
      },
      "source": [
        "Split training data into training and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN7GLO140iJQ"
      },
      "source": [
        "idx = np.random.rand(len(df)) < 0.8\n",
        "test_df = df[~idx]\n",
        "train_df = df[idx]\n",
        "test_df.reset_index(inplace=True)\n",
        "train_df.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcRD7j4KIQmE"
      },
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5_69qN0ZsJ6"
      },
      "source": [
        "def display_seismic_data(img_num, df):\n",
        "\n",
        "    #Create a pyplot with two images\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 8))\n",
        "\n",
        "    #Read Seismic image and corresponding mask\n",
        "    seismic_img = tf.keras.preprocessing.image.load_img('images/' + df.loc[img_num, 'id'] + '.png', color_mode='grayscale')\n",
        "\n",
        "    mask_img = tf.keras.preprocessing.image.load_img('masks/' + df.loc[img_num, 'id'] + '.png', color_mode='grayscale')\n",
        "    \n",
        "    #Show both images\n",
        "    ax1.set_title('Seismic')\n",
        "    ax1.imshow(seismic_img, cmap = 'seismic', interpolation = 'bilinear')\n",
        "    ax1.axis('off')\n",
        "    ax2.set_title('Salt')\n",
        "    ax2.imshow(mask_img, cmap = 'gray', interpolation = 'bilinear')\n",
        "    ax2.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdEkrp_MeArJ"
      },
      "source": [
        "#Try random images\n",
        "img_num = np.random.randint(0, train_df.shape[0])\n",
        "display_seismic_data(img_num, train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3DGC2ODvQJR"
      },
      "source": [
        "#### Build Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1uGqnTvvSUn"
      },
      "source": [
        "img_size = 128\n",
        "num_classes = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcg1SjtwvU2T"
      },
      "source": [
        "def batch_generator(df, batch_size=32):\n",
        "\n",
        "    while True:\n",
        "\n",
        "        #Create random indexes\n",
        "        idx = np.random.randint(0, df.shape[0], batch_size)\n",
        "\n",
        "        #Initialize numpy arrays for X and y\n",
        "        #Input image is size img_size,img_size,1\n",
        "        X = np.zeros((batch_size, img_size, img_size,1))\n",
        "        #Mask's size is img_size, img_size, 1\n",
        "        y = np.zeros((batch_size, img_size, img_size,num_classes))\n",
        "\n",
        "        #Populate X and y with actual data\n",
        "        for i in range(len(idx)):\n",
        "\n",
        "            #Read image\n",
        "            img = tf.keras.preprocessing.image.load_img('images/' + df.loc[idx[i],'id'] + '.png', color_mode='grayscale',\n",
        "                                                        target_size=(img_size, img_size))\n",
        "            img = tf.keras.preprocessing.image.img_to_array(img).astype('uint8')/255.0\n",
        "\n",
        "            X[i] = img\n",
        "\n",
        "            #Read mask\n",
        "            mask_img = tf.keras.preprocessing.image.load_img('masks/' + df.loc[idx[i],'id'] + '.png',\n",
        "                                                            color_mode = 'grayscale',\n",
        "                                                            target_size=(img_size, img_size))\n",
        "            mask_img = tf.keras.preprocessing.image.img_to_array(mask_img).astype('uint8')/255.0\n",
        "            mask_img = tf.keras.utils.to_categorical(mask_img, num_classes=num_classes)\n",
        "\n",
        "            y[i] = mask_img\n",
        "\n",
        "        yield X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBvPLdoguDRR"
      },
      "source": [
        "a = batch_generator(df, batch_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwxcLUmXuKNx"
      },
      "source": [
        "x, y = next(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hliBNZvnuMMU"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZIrPSZ9bdcn"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a-4hLBEuPsp"
      },
      "source": [
        "np.unique(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYayHQjwpz5c"
      },
      "source": [
        "#### Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayqMFpIxp2Yo"
      },
      "source": [
        "Function to create two Convolutional layer block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSB1lpP8q_B4"
      },
      "source": [
        "def conv2d_block(input_tensor, n_filters):\n",
        "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
        "    # first layer\n",
        "    x = tf.keras.layers.Conv2D(n_filters, (3,3), kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    # second layer\n",
        "    x = tf.keras.layers.Conv2D(n_filters, (3,3), kernel_initializer = 'he_normal', padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCliarJNsMt1"
      },
      "source": [
        "Function to build UNET Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L8VpW28sKS9"
      },
      "source": [
        "def build_unet(input_img, n_filters=16, dropout=0.1):\n",
        "\n",
        "    #ENCODER - DOWNSAMPLE the image - 128x128x1\n",
        "\n",
        "    #First Block\n",
        "    c1 = conv2d_block(input_img, n_filters*1) #128x128x16\n",
        "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1) #64x64x16\n",
        "    p1 = tf.keras.layers.Dropout(dropout)(p1) #64x64x16\n",
        "    #output will be 64x64x16 for image size 128x128x1\n",
        "\n",
        "    #Second Block\n",
        "    c2 = conv2d_block(p1, n_filters*2) #64x64x32\n",
        "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2) #32x32x32\n",
        "    p2 = tf.keras.layers.Dropout(dropout)(p2)\n",
        "    #output will be 32x32x32\n",
        "\n",
        "    #Third Block\n",
        "    c3 = conv2d_block(p2, n_filters*4) \n",
        "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "    p3 = tf.keras.layers.Dropout(dropout)(p3)\n",
        "    #output will be 16x16x64\n",
        "\n",
        "    #Fourth Block\n",
        "    c4 = conv2d_block(p3, n_filters*8) #16x16x128\n",
        "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
        "    p4 = tf.keras.layers.Dropout(dropout)(p4)\n",
        "    ##output will be 8x8x128 \n",
        "\n",
        "    #Fifth Block\n",
        "    c5 = conv2d_block(p4, n_filters*16)\n",
        "    #output will be 8x8x256\n",
        "\n",
        "    #We now have output of Encoder\n",
        "\n",
        "    #DECODER - UPSAMPLE the feature to generate mask\n",
        "\n",
        "    #First Block - connected to fourth block on DOWNSAMPLE side\n",
        "    u6 = tf.keras.layers.Conv2DTranspose(n_filters * 8, (3, 3), \n",
        "                                         strides = (2, 2), \n",
        "                                         padding = 'same')(c5) #16x16x128\n",
        "    u6 = tf.keras.layers.concatenate([u6, c4]) #16x16x256\n",
        "    u6 = tf.keras.layers.Dropout(dropout)(u6) \n",
        "    c6 = conv2d_block(u6, n_filters * 8) #16x16x128\n",
        "\n",
        "    #Second Block - connected to third block on DOWNSAMPLE side\n",
        "    u7 = tf.keras.layers.Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6) #32x32x64\n",
        "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "    u7 = tf.keras.layers.Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters * 4)\n",
        "\n",
        "    #Third Block - connected to second block on DOWNSAMPLE side\n",
        "    u8 = tf.keras.layers.Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7) #64x64\n",
        "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "    u8 = tf.keras.layers.Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters * 2) \n",
        "\n",
        "    #Fourth Block - connected to first block on DOWNSAMPLE side\n",
        "    u9 = tf.keras.layers.Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8) #128x128x16\n",
        "    u9 = tf.keras.layers.concatenate([u9, c1])\n",
        "    u9 = tf.keras.layers.Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters * 1) #128 x 128 x 16\n",
        "\n",
        "    #Build the Output layer\n",
        "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(c9) #128x128x1\n",
        "\n",
        "    #Build the model using different layers\n",
        "    model = tf.keras.Model(inputs=[input_img], outputs=[outputs])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVDUgizjvGm6"
      },
      "source": [
        "Build UNET model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRGoM5_zvEQB"
      },
      "source": [
        "#Clear out notebook session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Define input layer\n",
        "input_img = tf.keras.layers.Input((img_size, img_size, 1), name='input_img')\n",
        "\n",
        "#Build model\n",
        "model = build_unet(input_img, dropout=.3)\n",
        "\n",
        "#Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFK7c8BPVmFq"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL6lFjwPyR6r"
      },
      "source": [
        "Build training and test batch generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_6472sGyUVt"
      },
      "source": [
        "train_generator = batch_generator(train_df,batch_size=32)\n",
        "test_generator = batch_generator(test_df, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv42Vqy65VT6"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNIv4BCc4xjS"
      },
      "source": [
        "model.fit(train_generator,\n",
        "          steps_per_epoch=train_df.shape[0]//32, \n",
        "          validation_data=test_generator, \n",
        "          validation_steps=test_df.shape[0]//32, \n",
        "          epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDgS-vydTlbP"
      },
      "source": [
        "model = tf.keras.models.load_model('/gdrive/My Drive/TGS.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vysp8ixPTt9n"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erHNjYej7wXw"
      },
      "source": [
        "#### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-RQhs4x7x63"
      },
      "source": [
        "def display_model_prediction(img_num, df):\n",
        "\n",
        "    #Read Seismic image and corresponding mask\n",
        "    seismic_img = tf.keras.preprocessing.image.load_img('images/' + df.loc[img_num, 'id'] + '.png', color_mode='grayscale')\n",
        "    mask_img = tf.keras.preprocessing.image.load_img('masks/' + df.loc[img_num, 'id'] + '.png', color_mode='grayscale')\n",
        "\n",
        "    #Model prediction\n",
        "    test_img = seismic_img.resize((img_size, img_size))\n",
        "    test_img = tf.keras.preprocessing.image.img_to_array(test_img).astype('uint8')/255.0\n",
        "    test_img = np.expand_dims(test_img, axis=0) #1,128,128,1\n",
        "\n",
        "    pred = model.predict(test_img) #1,128,128,num_classes\n",
        "    \n",
        "    predicted_classes = np.argmax(pred[0], axis=-1)\n",
        "    #pred[0][pred[0] <0.5] = 0\n",
        "    #pred[0][pred[0] >=0.5] = 1    \n",
        "    #print(np.unique(pred[0]))\n",
        "    #Create a pyplot with two images\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (12, 8))\n",
        "\n",
        "    #Show both images\n",
        "    ax1.set_title('Seismic')\n",
        "    ax1.imshow(seismic_img, cmap = 'seismic', interpolation = 'bilinear')\n",
        "    ax2.set_title('Actual Salt')\n",
        "    ax2.imshow(mask_img, cmap = 'gray', interpolation = 'bilinear')\n",
        "    ax3.set_title('Predicted Salt')\n",
        "    ax3.imshow(np.reshape(predicted_classes,(img_size, img_size)), cmap = 'gray', interpolation = 'bilinear')\n",
        "\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xDWMQF_8dAp"
      },
      "source": [
        "img_num = np.random.randint(0, test_df.shape[0])\n",
        "display_model_prediction(img_num, test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpqfsHQaVg9g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPOOvHz8BIEI"
      },
      "source": [
        "img_num"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}